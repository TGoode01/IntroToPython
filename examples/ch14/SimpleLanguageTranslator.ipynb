{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convenience we've embedded the `SpokenResponse.wav` audio file at the bottom of this notebook so you can play a pre-recorded Spanish response to the English question \"Where is the closest bathroom?\" When the app asks for the Spanish response, press _Enter_ then click the audio's play button immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno -9998] Invalid number of channels",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 162\u001b[39m\n\u001b[32m    159\u001b[39m     pydub.playback.play(sound)\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m#if __name__ == '__main__':  # this is not needed in a notebook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[43mrun_translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m##########################################################################\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# (C) Copyright 2019 by Deitel & Associates, Inc. and                    #\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# Pearson Education, Inc. All Rights Reserved.                           #\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# furnishing, performance, or use of these programs.                     #\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m##########################################################################\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mrun_translator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Step 1: Prompt for then record English speech into an audio file\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mPress Enter then ask your question in English\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43menglish.wav\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Step 2: Transcribe the English speech to English text\u001b[39;00m\n\u001b[32m     20\u001b[39m english = speech_to_text(\n\u001b[32m     21\u001b[39m     file_name=\u001b[33m'\u001b[39m\u001b[33menglish.wav\u001b[39m\u001b[33m'\u001b[39m, model_id=\u001b[33m'\u001b[39m\u001b[33men-US_BroadbandModel\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 135\u001b[39m, in \u001b[36mrecord_audio\u001b[39m\u001b[34m(file_name)\u001b[39m\n\u001b[32m    132\u001b[39m recorder = pyaudio.PyAudio()  \u001b[38;5;66;03m# opens/closes audio streams\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# configure and open audio stream for recording (input=True)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m audio_stream = \u001b[43mrecorder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mFORMAT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCHANNELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFRAME_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_per_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m audio_frames = []  \u001b[38;5;66;03m# stores raw bytes of mic input\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRecording 5 seconds of audio\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edaci\\Documents\\datafun\\IntroToPython\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:639\u001b[39m, in \u001b[36mPyAudio.open\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    632\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Opens a new stream.\u001b[39;00m\n\u001b[32m    633\u001b[39m \n\u001b[32m    634\u001b[39m \u001b[33;03m    See constructor for :py:func:`PyAudio.Stream.__init__` for parameter\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    637\u001b[39m \u001b[33;03m    :returns: A new :py:class:`PyAudio.Stream`\u001b[39;00m\n\u001b[32m    638\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     stream = \u001b[43mPyAudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m     \u001b[38;5;28mself\u001b[39m._streams.add(stream)\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edaci\\Documents\\datafun\\IntroToPython\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:441\u001b[39m, in \u001b[36mPyAudio.Stream.__init__\u001b[39m\u001b[34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[39m\n\u001b[32m    438\u001b[39m     arguments[\u001b[33m'\u001b[39m\u001b[33mstream_callback\u001b[39m\u001b[33m'\u001b[39m] = stream_callback\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# calling pa.open returns a stream object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m \u001b[38;5;28mself\u001b[39m._stream = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m._input_latency = \u001b[38;5;28mself\u001b[39m._stream.inputLatency\n\u001b[32m    444\u001b[39m \u001b[38;5;28mself\u001b[39m._output_latency = \u001b[38;5;28mself\u001b[39m._stream.outputLatency\n",
      "\u001b[31mOSError\u001b[39m: [Errno -9998] Invalid number of channels"
     ]
    }
   ],
   "source": [
    "# SimpleLanguageTranslator.py\n",
    "\"\"\"Use IBM Watson Speech to Text, Language Translator and Text to Speech \n",
    "   APIs to enable English and Spanish speakers to communicate.\"\"\"\n",
    "from watson_developer_cloud import SpeechToTextV1\n",
    "from watson_developer_cloud import LanguageTranslatorV3\n",
    "from watson_developer_cloud import TextToSpeechV1\n",
    "import keys  # contains your API keys for accessing Watson services\n",
    "import pyaudio  # used to record from mic\n",
    "import pydub  # used to load a WAV file\n",
    "import pydub.playback  # used to play a WAV file\n",
    "import wave  # used to save a WAV file\n",
    "\n",
    "def run_translator():\n",
    "    \"\"\"Calls the functions that interact with Watson services.\"\"\"\n",
    "    # Step 1: Prompt for then record English speech into an audio file\n",
    "    input('Press Enter then ask your question in English')\n",
    "    record_audio('english.wav')\n",
    "\n",
    "    # Step 2: Transcribe the English speech to English text\n",
    "    english = speech_to_text(\n",
    "        file_name='english.wav', model_id='en-US_BroadbandModel')\n",
    "    print('English:', english)\n",
    "\n",
    "    # Step 3: Translate the English text into Spanish text\n",
    "    spanish = translate(text_to_translate=english, model='en-es')\n",
    "    print('Spanish:', spanish)\n",
    "\n",
    "    # Step 4: Synthesize the Spanish text into Spanish speech\n",
    "    text_to_speech(text_to_speak=spanish, \n",
    "        voice_to_use='es-US_SofiaVoice', file_name='spanish.wav')\n",
    "\n",
    "    # Step 5: Play the Spanish audio file\n",
    "    play_audio(file_name='spanish.wav')\n",
    "\n",
    "    # Step 6: Prompt for then record Spanish speech into an audio file\n",
    "    input('Press Enter then speak the Spanish answer')\n",
    "    record_audio('spanishresponse.wav')\n",
    "\n",
    "    # Step 7: Transcribe the Spanish speech to Spanish text\n",
    "    spanish = speech_to_text(\n",
    "        file_name='spanishresponse.wav', model_id='es-ES_BroadbandModel')\n",
    "    print('Spanish response:', spanish)\n",
    "\n",
    "    # Step 8: Translate the Spanish text into English text\n",
    "    english = translate(text_to_translate=spanish, model='es-en')\n",
    "    print('English response:', english)\n",
    "\n",
    "    # Step 9: Synthesize the English text into English speech\n",
    "    text_to_speech(text_to_speak=english,\n",
    "        voice_to_use='en-US_AllisonVoice',\n",
    "        file_name='englishresponse.wav')\n",
    "\n",
    "    # Step 10: Play the English audio\n",
    "    play_audio(file_name='englishresponse.wav')\n",
    "\n",
    "def speech_to_text(file_name, model_id):\n",
    "    \"\"\"Use Watson Speech to Text to convert audio file to text.\"\"\"\n",
    "    # create Watson Speech to Text client \n",
    "    stt = SpeechToTextV1(iam_apikey=keys.speech_to_text_key)\n",
    "\n",
    "    # open the audio file \n",
    "    with open(file_name, 'rb') as audio_file:\n",
    "        # pass the file to Watson for transcription\n",
    "        result = stt.recognize(audio=audio_file,\n",
    "            content_type='audio/wav', model=model_id).get_result()\n",
    "        \n",
    "    # Get the 'results' list. This may contain intermediate and final\n",
    "    # results, depending on method recognize's arguments. We asked \n",
    "    # for only final results, so this list contains one element.\n",
    "    results_list = result['results'] \n",
    "\n",
    "    # Get the final speech recognition result--the list's only element.\n",
    "    speech_recognition_result  = results_list[0]\n",
    "\n",
    "    # Get the 'alternatives' list. This may contain multiple alternative\n",
    "    # transcriptions, depending on method recognize's arguments. We did\n",
    "    # not ask for alternatives, so this list contains one element.\n",
    "    alternatives_list = speech_recognition_result['alternatives']\n",
    "\n",
    "    # Get the only alternative transcription from alternatives_list.\n",
    "    first_alternative = alternatives_list[0]\n",
    "\n",
    "    # Get the 'transcript' key's value, which contains the audio's \n",
    "    # text transcription.\n",
    "    transcript = first_alternative['transcript']\n",
    "\n",
    "    return transcript  # return the audio's text transcription\n",
    "\n",
    "def translate(text_to_translate, model):\n",
    "    \"\"\"Use Watson Language Translator to translate English to Spanish \n",
    "       (en-es) or Spanish to English (es-en) as specified by model.\"\"\"\n",
    "    # create Watson Translator client\n",
    "    language_translator = LanguageTranslatorV3(version='2018-05-31',\n",
    "        iam_apikey=keys.translate_key)\n",
    "\n",
    "    # perform the translation\n",
    "    translated_text = language_translator.translate(\n",
    "        text=text_to_translate, model_id=model).get_result()\n",
    "\n",
    "    # Get 'translations' list. If method translate's text argument has \n",
    "    # multiple strings, the list will have multiple entries. We passed\n",
    "    # one string, so the list contains only one element.\n",
    "    translations_list = translated_text['translations']\n",
    "    \n",
    "    # get translations_list's only element\n",
    "    first_translation = translations_list[0]\n",
    "\n",
    "    # get 'translation' key's value, witch is the translated text\n",
    "    translation = first_translation['translation']\n",
    "\n",
    "    return translation  # return the translated string\n",
    "\n",
    "def text_to_speech(text_to_speak, voice_to_use, file_name):\n",
    "    \"\"\"Use Watson Text to Speech to convert text to specified voice\n",
    "       and save to a WAV file.\"\"\"\n",
    "    # create Text to Speech client\n",
    "    tts = TextToSpeechV1(iam_apikey=keys.text_to_speech_key)\n",
    "\n",
    "    # open file and write the synthesized audio content into the file\n",
    "    with open(file_name, 'wb') as audio_file:\n",
    "        audio_file.write(tts.synthesize(text_to_speak, \n",
    "            accept='audio/wav', voice=voice_to_use).get_result().content)\n",
    "\n",
    "def record_audio(file_name):\n",
    "    \"\"\"Use pyaudio to record 5 seconds of audio to a WAV file.\"\"\"\n",
    "    FRAME_RATE = 44100  # number of frames per second\n",
    "    CHUNK = 1024  # number of frames read at a time\n",
    "    FORMAT = pyaudio.paInt16  # each frame is a 16-bit (2-byte) integer\n",
    "    CHANNELS = 2  # 2 samples per frame\n",
    "    SECONDS = 5  # total recording time\n",
    " \n",
    "    recorder = pyaudio.PyAudio()  # opens/closes audio streams\n",
    "\n",
    "    # configure and open audio stream for recording (input=True)\n",
    "    audio_stream = recorder.open(format=FORMAT, channels=CHANNELS, \n",
    "        rate=FRAME_RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    audio_frames = []  # stores raw bytes of mic input\n",
    "    print('Recording 5 seconds of audio')\n",
    "\n",
    "    # read 5 seconds of audio in CHUNK-sized pieces\n",
    "    for i in range(0, int(FRAME_RATE * SECONDS / CHUNK)):\n",
    "        audio_frames.append(audio_stream.read(CHUNK))\n",
    "\n",
    "    print('Recording complete')\n",
    "    audio_stream.stop_stream()  # stop recording\n",
    "    audio_stream.close()  \n",
    "    recorder.terminate()  # release underlying resources used by PyAudio\n",
    "\n",
    "    # save audio_frames to a WAV file\n",
    "    with wave.open(file_name, 'wb') as output_file:\n",
    "        output_file.setnchannels(CHANNELS)\n",
    "        output_file.setsampwidth(recorder.get_sample_size(FORMAT))\n",
    "        output_file.setframerate(FRAME_RATE)\n",
    "        output_file.writeframes(b''.join(audio_frames))\n",
    "\n",
    "def play_audio(file_name):\n",
    "    \"\"\"Use the pydub module (pip install pydub) to play a WAV file.\"\"\"\n",
    "    sound = pydub.AudioSegment.from_wav(file_name)\n",
    "    pydub.playback.play(sound)\n",
    "\n",
    "#if __name__ == '__main__':  # this is not needed in a notebook\n",
    "run_translator()\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# (C) Copyright 2019 by Deitel & Associates, Inc. and                    #\n",
    "# Pearson Education, Inc. All Rights Reserved.                           #\n",
    "#                                                                        #\n",
    "# DISCLAIMER: The authors and publisher of this book have used their     #\n",
    "# best efforts in preparing the book. These efforts include the          #\n",
    "# development, research, and testing of the theories and programs        #\n",
    "# to determine their effectiveness. The authors and publisher make       #\n",
    "# no warranty of any kind, expressed or implied, with regard to these    #\n",
    "# programs or to the documentation contained in these books. The authors #\n",
    "# and publisher shall not be liable in any event for incidental or       #\n",
    "# consequential damages in connection with, or arising out of, the       #\n",
    "# furnishing, performance, or use of these programs.                     #\n",
    "##########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio('SpokenResponse.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introtopython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
